# Machine Learning Coursework and Practice Problems

Author: Hunter Carroll

This repository showcases a combination of **theoretical foundations** and **hands-on implementations** in machine learning, completed as part of the **[CU Denver â€“ Machine Learning Methods](https://github.com/CU-Denver-MathStats-OER/Machine-Learning-Methods)** course. The work emphasizes practical model development using Python and standard ML libraries.

---

## Core Skills Demonstrated

- Linear and logistic regression (theory and implementation)
- Optimization methods (gradient descent, regularization)
- Supervised learning (SVMs, decision trees, random forests)
- Unsupervised learning (K-means clustering, PCA)
- Model evaluation and validation (metrics, cross-validation)
- Linear algebra and probability foundations for ML
- Python, NumPy, scikit-learn, and data visualization

---

## Machine Learning Theory (Proofs & Derivations)

This section contains written solutions and LaTeX-based proofs corresponding to the course  
[Machine Learning Methods](https://github.com/CU-Denver-MathStats-OER/Machine-Learning-Methods).  

**Highlighted topics:**

1. **Linear Regression and Ridge Regression**  
   Least squares in matrix form, normal equations, and closed-form ridge regression solutions.

2. **Logistic Regression and Softmax Regression**  
   Gradient derivations for binary and multiclass classification, including cross-entropy loss.

3. **Classification Metrics and Linear Decision Boundaries**  
   F1 score derivation, geometric interpretation of hyperplanes, and SVM bias/kernel formulations.

4. **Decision Trees**  
   Entropy, cross-entropy, information gain, and split evaluation criteria.

5. **Linear Algebra and Probability for Machine Learning**  
   Vector projections, covariance matrices, and Naive Bayes classification.

---

## Machine Learning Exercises

This section contains end-to-end programming assignments implementing core machine learning algorithms, including data exploration, model training, evaluation, and visualization.

1. **Linear Regression with Gradient Descent**  
   `linear-regression_gradient-descent_food-truck.ipynb`  
   Built a univariate linear regression model from scratch, visualized training data, implemented the cost function, and optimized parameters using gradient descent to predict business profit.

2. **Support Vector Machines (Linear and Kernel-Based)**  
   `support-vector-machines_linear-vs-kernel_C-regularization.ipynb`  
   Trained and compared linear SVMs with varying regularization strengths and implemented an RBF-kernel SVM to handle nonlinear decision boundaries.

3. **Decision Trees and Random Forests**  
   `decision-trees_random-forest_letter-classification.ipynb`  
   Performed supervised classification on the Letter Recognition (C vs. G) dataset, comparing single decision trees with ensemble-based random forests.

4. **Dimensionality Reduction and Classification (PCA + SVM)**  
   `pca_svm_mnist_hyperparameter-search.ipynb`  
   Applied PCA to reduce dimensionality of the MNIST dataset and trained an SVM classifier using pipelines and hyperparameter search for performance optimization.

5. **Unsupervised Learning with K-Means Clustering**  
   `kmeans_clustering_image-segmentation_elbow-method.ipynb`  
   Implemented K-means clustering for image segmentation, selected the number of clusters using the elbow method, and visualized clustering results.

---

## Matrix Methods and Numerical Linear Algebra

Additional projects and notes focused on matrix methods and numerical linear algebra for machine learning are planned and will be added to this repository.

---


Helpful Links and Good Resources: 
1. [Introduction to Machine Learning (I2ML)](https://slds-lmu.github.io/i2ml/)
